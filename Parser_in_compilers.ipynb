{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jornay/AC1-Teo-POO/blob/master/Parser_in_compilers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCmoqU968Rs5",
        "outputId": "ba4c2535-4fbd-4805-d779-6257cf612c3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<id a>', '<op *>', '<id b>', '<id A>', '<op =>', '<int 54>']\n",
            "<id a>\n",
            "<op *>\n",
            "<id b>\n",
            "<id A>\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "T_KEYWORD = \"keyword\"\n",
        "T_OP = \"op\"\n",
        "T_INT = \"int\"\n",
        "T_STRING = \"string\"\n",
        "T_ID = \"id\"\n",
        "T_EOF = \"eof\"\n",
        "\n",
        "class Token():\n",
        "\n",
        "    def __init__(self, tipo, valor=None):\n",
        "        self.tipo = tipo\n",
        "        self.valor = valor\n",
        "\n",
        "    def __str__(self):\n",
        "        return '<%s %s>' % (self.tipo, self.valor)\n",
        "\n",
        "\n",
        "class StopExecution(Exception):\n",
        "    def _render_traceback_(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "def afd_int(token):\n",
        "    try:\n",
        "        token = int(token)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def afd_string(token):\n",
        "    if token[0] == '\"' and token[-1] == '\"':\n",
        "        if '\"' not in token[1:-1]:\n",
        "            return True\n",
        "        else:\n",
        "            raise ValueError('Aspas em um local inesperado.')\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def afd_identificador(token):\n",
        "    regex = re.compile('[a-zA-Z0-9_]+')\n",
        "    r = regex.match(token)\n",
        "    if r is not None:\n",
        "        if r.group() == token:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def afd_principal(token):\n",
        "\n",
        "    if token == \"init\":\n",
        "        return Token(T_KEYWORD, 'init')\n",
        "\n",
        "    elif token in \"=+*/\":\n",
        "        return Token(T_OP, token)\n",
        "\n",
        "    elif afd_int(token):\n",
        "        return Token(T_INT, token)\n",
        "\n",
        "    elif afd_string(token):\n",
        "        return Token(T_STRING, token)\n",
        "\n",
        "    elif afd_identificador(token):\n",
        "        return Token(T_ID, token)\n",
        "\n",
        "    else:\n",
        "        raise ValueError('Valor inesperado')\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "class Parser():\n",
        "\n",
        "    def __init__(self, tokens):\n",
        "        self.tokens = tokens\n",
        "        self.pos = -1\n",
        "        self.token_atual = None\n",
        "\n",
        "        self.proximo()\n",
        "\n",
        "\n",
        "    def proximo(self):\n",
        "        self.pos += 1\n",
        "\n",
        "        if self.pos >= len(self.tokens):\n",
        "            self.token_atual = Token(T_EOF)\n",
        "        else:\n",
        "            self.token_atual = self.tokens[self.pos]\n",
        "\n",
        "        print(self.token_atual)\n",
        "        return self.token_atual\n",
        "\n",
        "\n",
        "    def erro(self):\n",
        "        raise Exception('Erro de sintaxe.')\n",
        "\n",
        "\n",
        "    def use(self, tipo, valor=None):\n",
        "\n",
        "        if self.token_atual.tipo != tipo:\n",
        "            self.erro()\n",
        "        elif valor is not None and self.token_atual.valor != valor:\n",
        "            self.erro()\n",
        "        else:\n",
        "            self.proximo()\n",
        "\n",
        "\n",
        "    def statement(self):\n",
        "        \"\"\"\n",
        "        statement ::= <id> <op => expr\n",
        "        \"\"\"\n",
        "        #Aqui é verificado se as operações fonecidadas pelo usuário\n",
        "        #não contem erro de sintaxe\n",
        "        self.use(T_ID);\n",
        "        self.use(T_OP);\n",
        "        self.expr();\n",
        "        pass\n",
        "\n",
        "\n",
        "    def expr(self):\n",
        "        \"\"\"\n",
        "        expr ::= term ( <op +> | <op -> term )*\n",
        "        \"\"\"\n",
        "\n",
        "        self.term()\n",
        "        while self.token_atual.tipo == T_OP and self.token_atual.valor in ['+','-', '*', '/']:\n",
        "            self.use(T_OP)\n",
        "            self.term()\n",
        "\n",
        "\n",
        "    def term(self):\n",
        "        \"\"\"\n",
        "        term ::= <id> | <int>\n",
        "        \"\"\"\n",
        "\n",
        "        if self.token_atual.tipo == T_INT:\n",
        "            self.use(T_INT)\n",
        "        elif self.token_atual.tipo == T_ID:\n",
        "            self.use(T_ID)\n",
        "        else:\n",
        "            self.erro()\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "\n",
        "arquivo = open('codigo.x','r')\n",
        "ln = 1\n",
        "\n",
        "tokens = []\n",
        "\n",
        "for l in arquivo.readlines():\n",
        "\n",
        "    # analisador lexico\n",
        "\n",
        "    l = l.replace('\\n','') # remove a quebra de linha\n",
        "\n",
        "    for token in l.split():\n",
        "        try:\n",
        "            tokens.append(afd_principal(token))\n",
        "        except Exception as e:\n",
        "            print(tokens)\n",
        "            print(str(e) + \" na posição %i da linha %i\" % (l.index(token), ln))\n",
        "            raise StopExecution\n",
        "    ln += 1\n",
        "\n",
        "print([str(t) for t in tokens])\n",
        "\n",
        "# analisador sintatico\n",
        "\n",
        "parser = Parser(tokens)\n",
        "parser.statement()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}